{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce86ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "✅ Models loaded!\n",
      "📸 Image: C:\\Users\\AbdulRahman\\Desktop\\tst1.jpg\n",
      "💬 User text: Amazing romantic dinner! #restaurant #romantic #datenight\n"
     ]
    }
   ],
   "source": [
    "# Install: pip install transformers torch pillow\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, BlipProcessor, BlipForConditionalGeneration, CLIPModel, CLIPProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "caption_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "text_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "print(\"✅ Models loaded!\")\n",
    "\n",
    "# Your inputs\n",
    "image_path = r\"C:\\Users\\AbdulRahman\\Desktop\\tst1.jpg\"\n",
    "user_text = \"Amazing romantic dinner! #restaurant #romantic #datenight\"\n",
    "\n",
    "print(f\"📸 Image: {image_path}\")\n",
    "print(f\"💬 User text: {user_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933ba351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 STEP 1: Image Description\n",
      "----------------------------------------\n",
      "🤖 AI sees in image: 'romantic couple in restaurant'\n",
      "\n",
      "🔍 STEP 2: Visual Classification Scores\n",
      "----------------------------------------\n",
      "   Restaurant: 0.964\n",
      "   Coffee: 0.907\n",
      "   Bar: 0.966\n",
      "   Fitness: 0.043\n",
      "   Spor: 0.718\n",
      "   Retail: 0.108\n",
      "   Romantic: 1.000\n",
      "   Family: 0.264\n",
      "   Trendy: 0.619\n",
      "   Casual: 0.890\n",
      "   Upscale: 0.990\n",
      "\n",
      "📊 VISUAL SCORES SUMMARY:\n",
      "   🏆 Romantic: 1.0\n",
      "   🏆 Upscale: 0.99\n",
      "   🏆 Bar: 0.966\n",
      "   🏆 Restaurant: 0.964\n",
      "   🏆 Coffee: 0.907\n"
     ]
    }
   ],
   "source": [
    "# Load and analyze image\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Step 1: Get image description using BLIP\n",
    "print(\"🔍 STEP 1: Image Description\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "inputs = caption_processor(image, return_tensors=\"pt\")\n",
    "out = caption_model.generate(**inputs, max_length=50)\n",
    "image_description = caption_processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"🤖 AI sees in image: '{image_description}'\")\n",
    "\n",
    "# Step 2: Visual classification using CLIP\n",
    "print(f\"\\n🔍 STEP 2: Visual Classification Scores\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define visual labels\n",
    "visual_labels = [\n",
    "    \"a restaurant with dining tables\",\n",
    "    \"a coffee shop or cafe\", \n",
    "    \"a bar with drinks\",\n",
    "    \"a fitness gym with equipment\",\n",
    "    \"a spa or beauty salon\",\n",
    "    \"a retail store with products\",\n",
    "    \"romantic atmosphere with candles\",\n",
    "    \"family place with kids\",\n",
    "    \"trendy modern design\",\n",
    "    \"casual comfortable setting\",\n",
    "    \"upscale elegant venue\"\n",
    "]\n",
    "\n",
    "visual_results = {}\n",
    "\n",
    "for label in visual_labels:\n",
    "    # Use CLIP to score image against each visual description\n",
    "    inputs = clip_processor(\n",
    "        text=[label, \"something completely different\"],\n",
    "        images=[image, image],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = clip_model(**inputs)\n",
    "        probs = outputs.logits_per_image.softmax(dim=-1)\n",
    "        score = probs[0, 0].item()  # Score for the positive label\n",
    "    \n",
    "    # Clean label name\n",
    "    clean_name = label.replace(\"a \", \"\").replace(\" with\", \"\").split()[0].title()\n",
    "    if \"romantic\" in label:\n",
    "        clean_name = \"Romantic\"\n",
    "    elif \"family\" in label:\n",
    "        clean_name = \"Family\"\n",
    "    elif \"trendy\" in label:\n",
    "        clean_name = \"Trendy\"\n",
    "    elif \"casual\" in label:\n",
    "        clean_name = \"Casual\"\n",
    "    elif \"upscale\" in label:\n",
    "        clean_name = \"Upscale\"\n",
    "    \n",
    "    visual_results[clean_name] = round(score, 3)\n",
    "    print(f\"   {clean_name}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 VISUAL SCORES SUMMARY:\")\n",
    "sorted_visual = sorted(visual_results.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_visual[:5]:\n",
    "    print(f\"   🏆 {name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d693d805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 STEP 3: Text Classification Scores\n",
      "----------------------------------------\n",
      "   Restaurant: 0.988\n",
      "   Coffee: 0.221\n",
      "   Bar: 0.429\n",
      "   Fitness: 0.174\n",
      "   Spa: 0.192\n",
      "   Retail: 0.190\n",
      "   Romantic: 0.980\n",
      "   Family: 0.241\n",
      "   Trendy: 0.676\n",
      "   Casual: 0.607\n",
      "   Upscale: 0.859\n",
      "\n",
      "📊 TEXT SCORES SUMMARY:\n",
      "   🏆 Restaurant: 0.988\n",
      "   🏆 Romantic: 0.98\n",
      "   🏆 Upscale: 0.859\n",
      "   🏆 Trendy: 0.676\n",
      "   🏆 Casual: 0.607\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔍 STEP 3: Text Classification Scores\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define text labels for classification\n",
    "text_labels = [\n",
    "    \"restaurant serving food and meals\",\n",
    "    \"coffee shop or cafe establishment\", \n",
    "    \"bar serving alcoholic drinks\",\n",
    "    \"fitness center or gym facility\",\n",
    "    \"spa or beauty salon services\",\n",
    "    \"retail store selling products\",\n",
    "    \"romantic atmosphere for couples\",\n",
    "    \"family-friendly place for children\",\n",
    "    \"trendy modern stylish venue\",\n",
    "    \"casual relaxed informal setting\",\n",
    "    \"upscale elegant expensive establishment\"\n",
    "]\n",
    "\n",
    "text_results = {}\n",
    "\n",
    "# Classify user text against each label\n",
    "for label in text_labels:\n",
    "    result = text_classifier(user_text, [label, \"unrelated content\"])\n",
    "    \n",
    "    # Get score for our target label\n",
    "    if result['labels'][0] == label:\n",
    "        score = result['scores'][0]\n",
    "    else:\n",
    "        score = result['scores'][1] if len(result['scores']) > 1 else 0.0\n",
    "    \n",
    "    # Clean label name\n",
    "    clean_name = label.split()[0].title()\n",
    "    if \"romantic\" in label:\n",
    "        clean_name = \"Romantic\"\n",
    "    elif \"family\" in label:\n",
    "        clean_name = \"Family\"\n",
    "    elif \"trendy\" in label:\n",
    "        clean_name = \"Trendy\"\n",
    "    elif \"casual\" in label:\n",
    "        clean_name = \"Casual\"\n",
    "    elif \"upscale\" in label:\n",
    "        clean_name = \"Upscale\"\n",
    "    \n",
    "    text_results[clean_name] = round(score, 3)\n",
    "    print(f\"   {clean_name}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 TEXT SCORES SUMMARY:\")\n",
    "sorted_text = sorted(text_results.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_text[:5]:\n",
    "    print(f\"   🏆 {name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9ac691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 STEP 4: Enhanced Text Analysis (Text + Image Description)\n",
      "----------------------------------------\n",
      "🔗 Enhanced text: 'Amazing romantic dinner! #restaurant #romantic #datenight. The image shows: romantic couple in restaurant'\n",
      "   Restaurant: 0.983\n",
      "   Coffee: 0.183\n",
      "   Bar: 0.304\n",
      "   Fitness: 0.133\n",
      "   Spa: 0.170\n",
      "   Retail: 0.150\n",
      "   Romantic: 0.996\n",
      "   Family: 0.263\n",
      "   Trendy: 0.547\n",
      "   Casual: 0.631\n",
      "   Upscale: 0.772\n",
      "\n",
      "📊 ENHANCED TEXT SCORES SUMMARY:\n",
      "   🏆 Romantic: 0.996\n",
      "   🏆 Restaurant: 0.983\n",
      "   🏆 Upscale: 0.772\n",
      "   🏆 Casual: 0.631\n",
      "   🏆 Trendy: 0.547\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔍 STEP 4: Enhanced Text Analysis (Text + Image Description)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Combine user text with image description for better context\n",
    "enhanced_text = f\"{user_text}. The image shows: {image_description}\"\n",
    "print(f\"🔗 Enhanced text: '{enhanced_text}'\")\n",
    "\n",
    "enhanced_text_results = {}\n",
    "\n",
    "# Classify enhanced text\n",
    "for label in text_labels:\n",
    "    result = text_classifier(enhanced_text, [label, \"unrelated content\"])\n",
    "    \n",
    "    if result['labels'][0] == label:\n",
    "        score = result['scores'][0]\n",
    "    else:\n",
    "        score = result['scores'][1] if len(result['scores']) > 1 else 0.0\n",
    "    \n",
    "    # Clean label name (same as before)\n",
    "    clean_name = label.split()[0].title()\n",
    "    if \"romantic\" in label:\n",
    "        clean_name = \"Romantic\"\n",
    "    elif \"family\" in label:\n",
    "        clean_name = \"Family\"\n",
    "    elif \"trendy\" in label:\n",
    "        clean_name = \"Trendy\"\n",
    "    elif \"casual\" in label:\n",
    "        clean_name = \"Casual\"\n",
    "    elif \"upscale\" in label:\n",
    "        clean_name = \"Upscale\"\n",
    "    \n",
    "    enhanced_text_results[clean_name] = round(score, 3)\n",
    "    print(f\"   {clean_name}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 ENHANCED TEXT SCORES SUMMARY:\")\n",
    "sorted_enhanced = sorted(enhanced_text_results.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_enhanced[:5]:\n",
    "    print(f\"   🏆 {name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d249a61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔗 STEP 5: Multi-Modal Fusion\n",
      "----------------------------------------\n",
      "Individual scores and fusion:\n",
      "   Casual:\n",
      "      Visual: 0.890\n",
      "      Text: 0.631\n",
      "      Fused: 0.735 → YES\n",
      "   Family:\n",
      "      Visual: 0.264\n",
      "      Text: 0.263\n",
      "      Fused: 0.263 → NO\n",
      "   Retail:\n",
      "      Visual: 0.108\n",
      "      Text: 0.150\n",
      "      Fused: 0.133 → NO\n",
      "   Romantic:\n",
      "      Visual: 1.000\n",
      "      Text: 0.996\n",
      "      Fused: 0.998 → YES\n",
      "   Upscale:\n",
      "      Visual: 0.990\n",
      "      Text: 0.772\n",
      "      Fused: 0.859 → YES\n",
      "   Restaurant:\n",
      "      Visual: 0.964\n",
      "      Text: 0.983\n",
      "      Fused: 0.975 → YES\n",
      "   Fitness:\n",
      "      Visual: 0.043\n",
      "      Text: 0.133\n",
      "      Fused: 0.097 → NO\n",
      "   Trendy:\n",
      "      Visual: 0.619\n",
      "      Text: 0.547\n",
      "      Fused: 0.576 → YES\n",
      "   Coffee:\n",
      "      Visual: 0.907\n",
      "      Text: 0.183\n",
      "      Fused: 0.473 → YES\n",
      "   Bar:\n",
      "      Visual: 0.966\n",
      "      Text: 0.304\n",
      "      Fused: 0.569 → YES\n",
      "\n",
      "🎯 FINAL FUSION RESULTS\n",
      "==================================================\n",
      "✅ DETECTED FEATURES:\n",
      "   🏆 Romantic: 0.998\n",
      "   🏆 Restaurant: 0.975\n",
      "   🏆 Upscale: 0.859\n",
      "   🏆 Casual: 0.735\n",
      "   🏆 Trendy: 0.576\n",
      "   🏆 Bar: 0.569\n",
      "   🏆 Coffee: 0.473\n",
      "\n",
      "📊 ALL SCORES (Top 5):\n",
      "   ✅ Romantic: 0.998 (V:1.0, T:0.996)\n",
      "   ✅ Restaurant: 0.975 (V:0.964, T:0.983)\n",
      "   ✅ Upscale: 0.859 (V:0.99, T:0.772)\n",
      "   ✅ Casual: 0.735 (V:0.89, T:0.631)\n",
      "   ✅ Trendy: 0.576 (V:0.619, T:0.547)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔗 STEP 5: Multi-Modal Fusion\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get common categories\n",
    "common_categories = set(visual_results.keys()) & set(enhanced_text_results.keys())\n",
    "\n",
    "fusion_results = {}\n",
    "\n",
    "print(\"Individual scores and fusion:\")\n",
    "for category in common_categories:\n",
    "    visual_score = visual_results.get(category, 0)\n",
    "    text_score = enhanced_text_results.get(category, 0)\n",
    "    \n",
    "    # Simple weighted fusion (60% text, 40% visual)\n",
    "    fused_score = 0.6 * text_score + 0.4 * visual_score\n",
    "    \n",
    "    fusion_results[category] = {\n",
    "        'visual': visual_score,\n",
    "        'text': text_score, \n",
    "        'fused': round(fused_score, 3),\n",
    "        'prediction': 'YES' if fused_score > 0.4 else 'NO'\n",
    "    }\n",
    "    \n",
    "    print(f\"   {category}:\")\n",
    "    print(f\"      Visual: {visual_score:.3f}\")\n",
    "    print(f\"      Text: {text_score:.3f}\")\n",
    "    print(f\"      Fused: {fused_score:.3f} → {fusion_results[category]['prediction']}\")\n",
    "\n",
    "print(f\"\\n🎯 FINAL FUSION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show positive predictions\n",
    "positive_predictions = []\n",
    "for category, scores in fusion_results.items():\n",
    "    if scores['prediction'] == 'YES':\n",
    "        positive_predictions.append((category, scores['fused']))\n",
    "\n",
    "if positive_predictions:\n",
    "    print(\"✅ DETECTED FEATURES:\")\n",
    "    for category, score in sorted(positive_predictions, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   🏆 {category}: {score}\")\n",
    "else:\n",
    "    print(\"❌ No features detected above threshold (0.4)\")\n",
    "\n",
    "print(f\"\\n📊 ALL SCORES (Top 5):\")\n",
    "sorted_final = sorted(fusion_results.items(), key=lambda x: x[1]['fused'], reverse=True)\n",
    "for category, scores in sorted_final[:5]:\n",
    "    status = \"✅\" if scores['prediction'] == 'YES' else \"❌\"\n",
    "    print(f\"   {status} {category}: {scores['fused']} (V:{scores['visual']}, T:{scores['text']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24e7fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 STEP 6: Method Comparison\n",
      "----------------------------------------\n",
      "How each method performed:\n",
      "\n",
      "1️⃣ VISUAL ONLY (CLIP + Image):\n",
      "   Romantic: 1.0\n",
      "   Upscale: 0.99\n",
      "   Bar: 0.966\n",
      "\n",
      "2️⃣ TEXT ONLY (User text):\n",
      "   Restaurant: 0.988\n",
      "   Romantic: 0.98\n",
      "   Upscale: 0.859\n",
      "\n",
      "3️⃣ ENHANCED TEXT (User text + Image description):\n",
      "   Romantic: 0.996\n",
      "   Restaurant: 0.983\n",
      "   Upscale: 0.772\n",
      "\n",
      "4️⃣ FUSION (60% Enhanced Text + 40% Visual):\n",
      "   Romantic: 0.998\n",
      "   Restaurant: 0.975\n",
      "   Upscale: 0.859\n",
      "\n",
      "💡 INSIGHTS:\n",
      "- Visual encoder good for: scene understanding, ambience detection\n",
      "- Text encoder good for: explicit mentions, hashtag analysis\n",
      "- Enhanced text good for: combining user intent with visual context\n",
      "- Fusion good for: balanced understanding of both modalities\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n📈 STEP 6: Method Comparison\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"How each method performed:\")\n",
    "print(\"\\n1️⃣ VISUAL ONLY (CLIP + Image):\")\n",
    "for name, score in sorted_visual[:3]:\n",
    "    print(f\"   {name}: {score}\")\n",
    "\n",
    "print(\"\\n2️⃣ TEXT ONLY (User text):\")\n",
    "for name, score in sorted_text[:3]:\n",
    "    print(f\"   {name}: {score}\")\n",
    "\n",
    "print(\"\\n3️⃣ ENHANCED TEXT (User text + Image description):\")\n",
    "for name, score in sorted_enhanced[:3]:\n",
    "    print(f\"   {name}: {score}\")\n",
    "\n",
    "print(\"\\n4️⃣ FUSION (60% Enhanced Text + 40% Visual):\")\n",
    "for category, scores in sorted_final[:3]:\n",
    "    print(f\"   {category}: {scores['fused']}\")\n",
    "\n",
    "print(f\"\\n💡 INSIGHTS:\")\n",
    "print(\"- Visual encoder good for: scene understanding, ambience detection\")\n",
    "print(\"- Text encoder good for: explicit mentions, hashtag analysis\") \n",
    "print(\"- Enhanced text good for: combining user intent with visual context\")\n",
    "print(\"- Fusion good for: balanced understanding of both modalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a80422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\AbdulRahman\\Desktop\\grad_folders\\MAIN_GRAD\\Travia\\Implementation\\AI\\test\\test_image_luxury_spa.jpg: 480x640 1 bicycle, 2 chairs, 341.4ms\n",
      "Speed: 14.0ms preprocess, 341.4ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "🧠 Detected objects:\n",
      " - bicycle\n",
      " - chair\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained YOLOv8 model (you can try 'yolov8n.pt' for faster results)\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# Path to your image\n",
    "image_path = r\"C:\\Users\\AbdulRahman\\Desktop\\grad_folders\\MAIN_GRAD\\Travia\\Implementation\\AI\\test\\test_image_luxury_spa.jpg\"\n",
    "\n",
    "# Run inference\n",
    "results = model(image_path)\n",
    "\n",
    "# Show the image with bounding boxes (optional)\n",
    "results[0].show()\n",
    "\n",
    "# Or save the image with results\n",
    "results[0].save(filename=\"output_with_boxes.jpg\")\n",
    "\n",
    "# Get detected object names\n",
    "detected_objects = results[0].names\n",
    "detected_ids = results[0].boxes.cls.cpu().tolist()  # get class IDs\n",
    "\n",
    "# Map class IDs to object names\n",
    "object_labels = [detected_objects[int(cls_id)] for cls_id in detected_ids]\n",
    "\n",
    "# Print out detected objects\n",
    "print(\"🧠 Detected objects:\")\n",
    "for label in set(object_labels):\n",
    "    print(f\" - {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edb544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
