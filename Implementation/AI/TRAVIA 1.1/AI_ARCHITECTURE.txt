================================================================================
                    TRAVEL AI METADATA LEARNING SYSTEM ARCHITECTURE
================================================================================

OVERVIEW
========
This system combines reinforcement learning (PPO) with metadata-based content filtering 
to provide personalized travel recommendations that learn from user interactions. The AI 
analyzes user behavior patterns across multiple dimensions: atmosphere preferences 
(romantic, classy, calm), cuisine types, price ranges, and location preferences.

================================================================================
CORE AI COMPONENTS
================================================================================

1. TRAVEL RECOMMENDATION SYSTEM CLASS
-------------------------------------
Main orchestrator that coordinates all AI components:

   - Content-Based Filtering Engine
   - Metadata Learning Processor  
   - PPO Reinforcement Learning Agent
   - User Preference Analyzer
   - Business Compatibility Scorer

2. PPO REINFORCEMENT LEARNING AGENT
-----------------------------------
Neural Network Architecture:
   - State Dimension: 25 features (increased to include metadata)
   - Action Dimension: 2 (Like/Dislike)
   - Hidden Layers: 128 neurons each
   
   Actor Network:
   Input(25) → Linear(128) → ReLU → Linear(128) → ReLU → Linear(2) → Softmax
   
   Critic Network:
   Input(25) → Linear(128) → ReLU → Linear(128) → ReLU → Linear(1)
   
   Training Parameters:
   - Learning Rate: 0.001
   - Epsilon (clipping): 0.3 (increased for aggressive learning)
   - Training Epochs: 10 per update
   - Optimizer: Adam

3. METADATA LEARNING ENGINE
---------------------------
Analyzes user interactions to extract preference patterns:

   Binary Attribute Analysis:
   - Calm preference score (0-1)
   - Noisy preference score (0-1) 
   - Romantic preference score (0-1)
   - Good for kids preference score (0-1)
   - Classy preference score (0-1)
   - Casual preference score (0-1)
   - Family-friendly preference score (0-1)

   Categorical Preference Learning:
   - Cuisine type preferences (ranked by frequency)
   - Price range preferences (1-4 scale)
   - Location preferences (city/state combinations)

4. CONTENT-BASED FILTERING ENGINE
---------------------------------
Enhanced with metadata integration:
   - Traditional feature matching (budget, travel style, accommodation)
   - Metadata preference integration (0.6 weight multiplier)
   - Learned pattern application from user history
   - Aggressive filtering based on negative patterns

================================================================================
DATA FLOW ARCHITECTURE
================================================================================

INPUT LAYER
-----------
User Preferences Form:
├── Budget (1-4 scale)
├── Travel Days (1-14)
├── Travel Style (tourist/local)
├── Noise Preference (calm/noisy)
├── Family Friendly (boolean)
├── Accommodation Type (hotel/hostel/airbnb)
├── Preferred Cuisines (multi-select)
├── Ambience Preference (casual/classy)
└── Good for Kids (boolean)

User Interactions:
├── Like/Dislike Actions
├── Business IDs
├── Interaction Timestamps
└── Context Preferences

PROCESSING LAYER
---------------
1. User Feature Vector Creation (25 dimensions):
   [0-9]   Basic preferences (budget, days, style, etc.)
   [10-16] Metadata preferences (romantic, classy, calm, etc.)
   [17-24] Padding/additional features

2. Business Feature Vector Creation (25 dimensions):
   [0-9]   Business attributes (stars, reviews, price, amenities)
   [10-16] Mapped metadata attributes
   [17-24] Padding/additional features

3. Metadata Analysis Pipeline:
   User Likes → Post Metadata → Preference Calculation → Score Normalization

4. Content Filtering Pipeline:
   Business Pool → User Preferences → Metadata Integration → Ranking

5. PPO Training Pipeline:
   Interactions → State-Action Pairs → Reward Calculation → Model Update

OUTPUT LAYER
-----------
Ranked Business Recommendations:
├── Content Score (traditional filtering)
├── RL Score (PPO confidence)
├── Metadata Compatibility Score
└── Final Combined Ranking

================================================================================
LEARNING MECHANISMS
================================================================================

1. METADATA PREFERENCE LEARNING
------------------------------
Algorithm: Frequency-based preference extraction

For each metadata attribute:
   preference_score = liked_posts_with_attribute / total_liked_posts

Learning Triggers:
   - Minimum 2 liked posts required
   - Real-time updates after each interaction
   - Preference recalculation on each recommendation request

2. REINFORCEMENT LEARNING (PPO)
------------------------------
State Representation:
   - User preference vector (10 features)
   - Metadata preference vector (7 features)  
   - Business feature vector (averaged for state)

Reward Function:
   - Base Reward: +2.0 for likes, -2.0 for dislikes
   - Metadata Bonus: +1.0 × metadata_compatibility_score for likes
   - Enhanced reward based on preference alignment

Training Strategy:
   - Minimum 2 interactions before training
   - 10 epochs per training session
   - Aggressive epsilon (0.3) for faster learning

3. PATTERN RECOGNITION
---------------------
Negative Pattern Learning:
   - Exact business name blocking
   - Keyword extraction and penalization
   - Price range avoidance
   - Cuisine type filtering

Positive Pattern Learning:
   - Feature preference weighting
   - Budget optimization
   - Ambience preference strengthening

================================================================================
FEATURE ENGINEERING
================================================================================

1. USER FEATURES
---------------
Static Features:
   - Budget (normalized 0-1)
   - Travel days (normalized 0-1)
   - Style preference (binary)
   - Accommodation type (one-hot)

Dynamic Features (Learned):
   - Metadata preferences (7 dimensions)
   - Cuisine preferences (ranked)
   - Price range preferences
   - Location preferences

2. BUSINESS FEATURES
-------------------
Objective Features:
   - Star rating (normalized 0-1)
   - Review count (normalized 0-1)
   - Price range (normalized 0-1)

Subjective Features:
   - Ambience attributes (binary)
   - Service features (binary)
   - Good-for attributes (binary)

Mapped Metadata:
   - Calm/Noisy mapping
   - Romantic attribute detection
   - Family-friendly assessment
   - Cuisine type classification

3. COMPATIBILITY SCORING
-----------------------
Algorithm: Weighted attribute matching

For each business:
   score = Σ(user_preference[i] × business_attribute[i] × weight[i])
   
Weight Distribution:
   - Romantic matching: 0.4
   - Good for kids: 0.35
   - Classy/Casual: 0.3
   - Calm/Noisy: 0.25-0.3
   - Cuisine matching: 0.5
   - Price matching: 0.3
   - Location matching: 0.2

================================================================================
DATABASE INTEGRATION
================================================================================

CORE TABLES
----------
1. users: User profiles and authentication
2. posts: Content with location and caption data
3. metadata: Post attributes (calm, romantic, classy, cuisine, price)
4. likes: User interactions with posts (metadata learning)
5. user_interactions: User feedback on recommendations (reinforcement learning)
6. businesses: Venue data with comprehensive attributes
7. user_preferences: Initial preference settings

DUAL LIKE SYSTEM TABLES
-----------------------
likes table (Post Likes - Metadata Learning):
├── id (TEXT, primary key)
├── liker_user_id (TEXT, who liked the post)
├── liked_user_id (TEXT, post author)
├── post_id (TEXT, FK to posts - the liked content)
├── comment_id (TEXT, optional)
├── created_at (TIMESTAMP)
├── story_id (TEXT, optional)
└── type (TEXT, 'like' or 'dislike')

user_interactions table (Business Likes - Reinforcement Learning):
├── id (SERIAL, primary key)
├── user_id (TEXT, who gave feedback)
├── business_id (TEXT, FK to businesses - the rated venue)
├── interaction_type (TEXT, 'like' or 'dislike')
├── context_preferences (JSON, user state during interaction)
└── created_at (TIMESTAMP, default current_timestamp)

METADATA SCHEMA
--------------
metadata table structure:
├── post_id (TEXT, FK to posts)
├── calm (INTEGER, 0/1)
├── noisy (INTEGER, 0/1)  
├── romantic (INTEGER, 0/1)
├── good_for_kids (INTEGER, 0/1)
├── classy (INTEGER, 0/1)
├── casual (INTEGER, 0/1)
├── family_friendly_places (INTEGER, 0/1)
├── location (TEXT)
├── cuisine_type (TEXT)
└── price_range (INTEGER, 1-4)

LEARNING QUERIES
---------------
Metadata Learning Query (Post Likes):
```sql
SELECT m.* FROM likes l
JOIN metadata m ON l.post_id = m.post_id
WHERE l.liker_user_id = ? AND l.type = 'like'
ORDER BY l.created_at DESC
```
Purpose: Extract metadata preferences from liked posts

Reinforcement Learning Query (Business Likes):
```sql
SELECT ui.*, b.* FROM user_interactions ui
JOIN businesses b ON ui.business_id = b.id
WHERE ui.user_id = ?
ORDER BY ui.created_at DESC
```
Purpose: Get business feedback for PPO model training

Business compatibility query:
```sql
SELECT * FROM businesses 
WHERE (stars >= 3.0 OR stars IS NULL)
AND name IS NOT NULL 
ORDER BY stars DESC, review_count DESC
```
Purpose: Get candidate businesses for recommendation filtering

================================================================================
PERSONALIZATION STRATEGY
================================================================================

1. COLD START PROBLEM
---------------------
New User Approach:
   - Use initial preference form
   - Default metadata weights (0.5 for all attributes)
   - Gradual learning after 2+ interactions

2. PREFERENCE EVOLUTION
----------------------
Learning Stages:
   Stage 1 (0-2 interactions): Form-based recommendations
   Stage 2 (3-5 interactions): Basic pattern recognition
   Stage 3 (6-10 interactions): Strong metadata learning
   Stage 4 (11+ interactions): Sophisticated preference modeling

3. RECOMMENDATION MIXING
-----------------------
Recommendation Sources:
   - Content-based filtering: 40%
   - Metadata compatibility: 60%
   - PPO confidence scoring: Applied post-filtering
   - Diversity injection: Ensure variety in recommendations

================================================================================
PERFORMANCE OPTIMIZATION
================================================================================

1. CACHING STRATEGY
------------------
- User preference caching in session
- Business vector pre-computation
- Metadata analysis caching per user

2. BATCH PROCESSING
------------------
- PPO training in batches (10 epochs)
- Business filtering in chunks
- Metadata analysis optimization

3. REAL-TIME UPDATES
-------------------
- Immediate preference recalculation
- On-demand model updates
- Session-based preference storage

================================================================================
SCALABILITY DESIGN
================================================================================

1. MODULAR ARCHITECTURE
-----------------------
Each component is independently scalable:
   - Metadata Learning Engine (stateless)
   - PPO Agent (model-based, serializable)
   - Content Filter (database-dependent)
   - Business Scorer (computation-heavy)

2. DATABASE OPTIMIZATION
-----------------------
- Indexed foreign keys for join performance
- Metadata table optimized for preference queries
- Business table indexed on rating and reviews

3. HORIZONTAL SCALING
--------------------
- User-based partitioning possible
- Stateless recommendation generation
- Model serialization for distributed training

================================================================================
EVALUATION METRICS
================================================================================

1. LEARNING EFFECTIVENESS
-------------------------
- Preference convergence rate
- Interaction-to-satisfaction correlation
- Recommendation diversity maintenance

2. SYSTEM PERFORMANCE
--------------------
- Response time for recommendations
- Database query optimization
- Memory usage for model storage

3. USER ENGAGEMENT
-----------------
- Like/dislike ratio improvement
- Session duration increase
- Return user rate

================================================================================
FUTURE ENHANCEMENTS
================================================================================

1. ADVANCED LEARNING
--------------------
- Deep learning for preference embedding
- Collaborative filtering integration
- Time-based preference evolution

2. CONTEXT AWARENESS
-------------------
- Time-of-day preferences
- Weather-based recommendations
- Social context integration

3. MULTI-MODAL LEARNING
----------------------
- Image-based preference extraction
- Natural language preference analysis
- Social media integration

================================================================================
TECHNICAL SPECIFICATIONS
================================================================================

Programming Language: Python 3.x
Web Framework: Flask
Database: PostgreSQL (Port 5433)
ML Libraries: PyTorch, scikit-learn, NumPy, Pandas
Frontend: HTML5, Bootstrap 5, JavaScript ES6

Model Storage: In-memory (PPO agent)
Session Management: Flask sessions
Database Connection: psycopg2 with connection pooling

Performance Characteristics:
- Cold start: <500ms
- Warm recommendations: <200ms  
- PPO training: <1s for 10 epochs
- Metadata analysis: <100ms

================================================================================
DUAL LEARNING SYSTEM - TWO TYPES OF LIKES
================================================================================

CRITICAL DISTINCTION: This system uses TWO separate like mechanisms for different AI purposes:

1. POST LIKES (Social Media Style)
---------------------------------
Purpose: Metadata preference learning
Table: "likes" table
Target: User-generated posts about places
Learning Component: Metadata Learning Engine

Schema:
├── liker_user_id (who liked the post)
├── post_id (which post was liked)  
├── type ('like' or 'dislike')
└── created_at (timestamp)

Flow: User likes posts → System extracts metadata → Learns atmosphere preferences

Example: User likes a post about a "romantic Italian restaurant" 
→ System learns user prefers romantic places and Italian cuisine

2. BUSINESS LIKES (Recommendation Feedback)
------------------------------------------
Purpose: Reinforcement learning and recommendation improvement
Table: "user_interactions" table  
Target: Businesses in itinerary recommendations
Learning Component: PPO Reinforcement Learning Agent

Schema:
├── user_id (who gave feedback)
├── business_id (which business was rated)
├── interaction_type ('like' or 'dislike')
└── context_preferences (user state at time of interaction)

Flow: User likes/dislikes recommendations → PPO model trains → Better future recommendations

Example: User dislikes "McDonald's" in itinerary 
→ PPO learns to avoid similar fast food chains for this user

INTEGRATION: Both systems work together
- Post likes provide semantic understanding (WHAT user prefers)
- Business likes provide behavioral feedback (HOW user responds to recommendations)

================================================================================

This architecture provides a robust, scalable, and highly personalized travel 
recommendation system that learns continuously from user interactions while 
maintaining transparency and user trust through explainable AI decisions. 